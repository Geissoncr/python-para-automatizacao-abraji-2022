{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Raspagem de dados de segurança pública\n",
        "### Oficina na Abraji de 2022 sobre automação com Python"
      ],
      "metadata": {
        "id": "OS7qZ9yv1qx5"
      },
      "id": "OS7qZ9yv1qx5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Carregar as bibliotecas"
      ],
      "metadata": {
        "id": "RPanGjFdtrpB"
      },
      "id": "RPanGjFdtrpB"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f81bc7bd",
      "metadata": {
        "id": "f81bc7bd"
      },
      "outputs": [],
      "source": [
        "import requests # importante para a raspagem de dados\n",
        "from bs4 import BeautifulSoup # importante para a raspagem de dados\n",
        "import pandas as pd # importante para a análise de dados e mexer com DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Informar o site"
      ],
      "metadata": {
        "id": "PrsPhxNwt1Pp"
      },
      "id": "PrsPhxNwt1Pp"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bbf85e7a",
      "metadata": {
        "id": "bbf85e7a"
      },
      "outputs": [],
      "source": [
        "link = 'https://www.ssp.sp.gov.br/estatistica/ViolenciaMulher.aspx' # site que vamos raspar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Ler o HTML do site\n"
      ],
      "metadata": {
        "id": "t0CwbSEQt86Q"
      },
      "id": "t0CwbSEQt86Q"
    },
    {
      "cell_type": "code",
      "source": [
        "page = requests.get(link) # requisitação do site que vamos raspar; o site foi informado acima\n",
        "soup = BeautifulSoup(page.text) # page.text é o html e aqui ainda teremos ele identado (ou seja, organizado)"
      ],
      "metadata": {
        "id": "jFxxYFpGt8Dv"
      },
      "id": "jFxxYFpGt8Dv",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Informar o elemento de nosso interesse.\n",
        "Por exemplo, qual é o `h3` do site?"
      ],
      "metadata": {
        "id": "LjVn9yZtuacN"
      },
      "id": "LjVn9yZtuacN"
    },
    {
      "cell_type": "code",
      "source": [
        "# h3, citado dentro de find(), é um elemento do HTML\n",
        "# ele é um texto importante, embora menos importante que h1 e h2\n",
        "h3_link = soup.find('h3')\n",
        "print(h3_link) #o print é usado para mostrar o que tem dentro da variável"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz-efe0PudNb",
        "outputId": "08eb78a7-33e4-4957-c0d7-cf1dc02f3d6e"
      },
      "id": "Qz-efe0PudNb",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<h3 style=\"color: #666;\"><b>Violência Contra as Mulheres</b></h3>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. E sem o HTML, apenas o texto?"
      ],
      "metadata": {
        "id": "RVu6D7kDyf7w"
      },
      "id": "RVu6D7kDyf7w"
    },
    {
      "cell_type": "code",
      "source": [
        "# aqui vamos sobrescrever a variável\n",
        "# observe que usamos 'find', e não 'find_all', então pegamos apenas o primeiro elemento\n",
        "h3_link = soup.find('h3').text\n",
        "print(h3_link)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnMvl3htvGk5",
        "outputId": "05993fb4-2ac7-4f7f-943f-d16a29da59f4"
      },
      "id": "nnMvl3htvGk5",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Violência Contra as Mulheres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. E se quiséssemos as `divs`?"
      ],
      "metadata": {
        "id": "SghUPu5EvUAs"
      },
      "id": "SghUPu5EvUAs"
    },
    {
      "cell_type": "code",
      "source": [
        "# observe que agora usamos 'find_all' em vez de 'find'\n",
        "# no HTML, o element 'div' é usado para guardar diversos elementos\n",
        "divs_link = soup.find_all(\"div\", id=True) # pega só as divs que têm id, por isso id é True"
      ],
      "metadata": {
        "id": "x_33qKxNvnjn"
      },
      "id": "x_33qKxNvnjn",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Agora podemos falar: para cada `div`, pegue a tabela.\n",
        "Para isso, usamos um loop, ou seja, uma estrutura de repetição."
      ],
      "metadata": {
        "id": "XWOxTOtVvCrT"
      },
      "id": "XWOxTOtVvCrT"
    },
    {
      "cell_type": "code",
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\", id=True) \n",
        "\n",
        "##### código novo\n",
        "# para cada div, vamos pegar as tabelas que estão dentro (quando houver)\n",
        "# aqui, pela primeira vez no notebook, vamos um loop, ou seja, uma estrutura de repetição\n",
        "for div in divs_link:\n",
        "    tabelas = div.find_all(\"table\")  #table é um elemento do html para criar uma tabela\n",
        "    #print(tabelas) # deixamos esta linha comentada pois há muitas linhas"
      ],
      "metadata": {
        "id": "CWu90AGfwSQ1"
      },
      "id": "CWu90AGfwSQ1",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Agora vamos usar uma estrutura condicional.\n",
        "O `if` nos ajuda a começar a estruturar os dados raspados. Queremos os dados sem sujeira em um formato [tidy](https://escoladedados.org/tutoriais/tidy-data-dados-arrumados-e-5-problemas-comuns/) (ou seja, cada coluna é uma variável)."
      ],
      "metadata": {
        "id": "ldlteLsSwpYO"
      },
      "id": "ldlteLsSwpYO"
    },
    {
      "cell_type": "code",
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\", id=True) \n",
        "\n",
        "for div in divs_link:\n",
        "    tabelas = div.find_all('table') \n",
        "\n",
        "##### código novo\n",
        "    # agora usamos um if, também muito usado junto com ifelse e else, para criar condições\n",
        "    if(tabelas): # se a div tiver tabela...\n",
        "      titulos = div.find_all('b') # coletar o elemento 'b', onde está o texto com a data da tabela\n",
        "      if(titulos): # se o elemento for encontrado... \n",
        "        data = str(titulos[0].get_text())[33:].split(' ') #  pegar a data da tabela; 33 é o número caracteres em 'Ocorrências Registradas no mês:', que vem antes da data; split separa considerando o espaço os textos que compõem a data ['junho', 'de', '2022']"
      ],
      "metadata": {
        "id": "bszTGNxDwl-j"
      },
      "id": "bszTGNxDwl-j",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Vamos também informar o que é cabeçalho e o que é dado na nossa `tabela`"
      ],
      "metadata": {
        "id": "f12xt9aIxnrs"
      },
      "id": "f12xt9aIxnrs"
    },
    {
      "cell_type": "code",
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\", id=True) \n",
        "\n",
        "for div in divs_link:\n",
        "    tabelas = div.find_all(\"table\")\n",
        "    if(tabelas): \n",
        "      titulos = div.find_all('b')\n",
        "      if(titulos): \n",
        "        data = str(titulos[0].get_text())[33:].split(' ') \n",
        "\n",
        "##### código novo\n",
        "        final_data = [] #criamos uma lista vazia; vamos usar apenas na etapa 11\n",
        "        # novamente usamos um loop para repetir uma ação\n",
        "        for tabela in tabelas: # para cada tabela...\n",
        "          linhas = tabela.find_all(\"tr\") # encontre todos os elementos 'tr' - r vem de 'row', ou seja, linha\n",
        "          cabecalhos = linhas[0].find_all(\"th\") # na primeira linha encontre todos os 'th' - h vem de 'header', ou seja, cabeçalho\n",
        "          #print(linhas)"
      ],
      "metadata": {
        "id": "w9f0AcOQxoN3"
      },
      "id": "w9f0AcOQxoN3",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Agora vamos fazer um novo loop para tratar os dados coletados para o cabeçalho"
      ],
      "metadata": {
        "id": "4YDBmT0f3s99"
      },
      "id": "4YDBmT0f3s99"
    },
    {
      "cell_type": "code",
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\", id=True) \n",
        "\n",
        "for div in divs_link:\n",
        "    tabelas = div.find_all(\"table\")\n",
        "    if(tabelas): \n",
        "      titulos = div.find_all('b')\n",
        "      if(titulos): \n",
        "        data = str(titulos[0].get_text())[33:].split(' ')\n",
        "        final_data = []\n",
        "        for tabela in tabelas: \n",
        "          linhas = tabela.find_all(\"tr\") \n",
        "          cabecalhos = linhas[0].find_all(\"th\") \n",
        "          #print(linhas)\n",
        "\n",
        "##### código novo\n",
        "          cabecalhos_all = [] # criamos uma lista vazia onde futuramente vamos colocar conteúdo\n",
        "          for cabecalho in cabecalhos: # para cada item dentro de cabecalhos...\n",
        "            cabecalhos_all.append(str(cabecalho.text).replace('\\xa0','crime')) # substitui '\\xa0' por 'crime' e guarde dentro de 'cabecalhos_all'; observe que no html a primeira coluna ta cabeçalho em branco"
      ],
      "metadata": {
        "id": "UCeWKGjb3sH3"
      },
      "id": "UCeWKGjb3sH3",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Agora vamos fazer novos loops para pegar cada número e tratá-los.\n",
        "\n"
      ],
      "metadata": {
        "id": "W1jt1DIBuhmx"
      },
      "id": "W1jt1DIBuhmx"
    },
    {
      "cell_type": "code",
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\", id=True) \n",
        "\n",
        "for div in divs_link:\n",
        "    tabelas = div.find_all(\"table\")\n",
        "    if(tabelas): \n",
        "      titulos = div.find_all('b')\n",
        "      if(titulos): \n",
        "        data = str(titulos[0].get_text())[33:].split(' ')\n",
        "\n",
        "      final_data = [] \n",
        "      for tabela in tabelas: \n",
        "        linhas = tabela.find_all(\"tr\") \n",
        "        cabecalhos = linhas[0].find_all(\"th\") \n",
        "        #print(linhas)\n",
        "        cabecalhos_all = []\n",
        "\n",
        "        for cabecalho in cabecalhos: \n",
        "          cabecalhos_all.append(str(cabecalho.text).replace('\\xa0','crime')) \n",
        "\n",
        "##### código novo\n",
        "\n",
        "          for linha in linhas[1:]: # em cada linha, exceto na primeira (que é o cabeçalho)...\n",
        "            dados = linha.find_all(\"td\") # encontre todos os elementos 'td' - ou seja, cada célula/item da tabela \n",
        "            dados_all = [] # criamos uma lista vazia onde logo abaixo vamos colocar conteúdo\n",
        "\n",
        "            for dado in dados: # para cada item dentro de 'dados'...\n",
        "              dados_all.append(str(dado.text).replace('\\n','')) # delete '\\n' - quando houver - e guarde dentro o texto de 'dado' em 'dados_all'"
      ],
      "metadata": {
        "id": "B3eh_EqiuiRJ"
      },
      "id": "B3eh_EqiuiRJ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Agora vamos colocar o conteúdo coletado referente a mês e ano de cada linha em 'dados_all', que já tinha os nossos dados/estatísticas de segurança. Vamos também fazer com que esses dados entrem em um arquivo final com os dados.\n"
      ],
      "metadata": {
        "id": "dlvbc_sN0scP"
      },
      "id": "dlvbc_sN0scP"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b12899e5",
      "metadata": {
        "id": "b12899e5"
      },
      "outputs": [],
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\", id=True) \n",
        "\n",
        "for div in divs_link:\n",
        "\n",
        "    tabelas = div.find_all(\"table\")\n",
        "    if(tabelas): \n",
        "      titulos = div.find_all('b')\n",
        "      if(titulos): \n",
        "        data = str(titulos[0].get_text())[33:].split(' ')\n",
        "\n",
        "        final_data = []\n",
        "        for tabela in tabelas: \n",
        "          linhas = tabela.find_all(\"tr\") \n",
        "          cabecalhos = linhas[0].find_all(\"th\") \n",
        "          #print(linhas)\n",
        "          cabecalhos_all = []\n",
        "\n",
        "          for cabecalho in cabecalhos: \n",
        "            cabecalhos_all.append(str(cabecalho.text).replace('\\xa0','crime')) \n",
        "\n",
        "          for linha in linhas[1:]: \n",
        "            dados = linha.find_all(\"td\") \n",
        "            \n",
        "            dados_all = [] \n",
        "            for dado in dados: \n",
        "              dados_all.append(str(dado.text).replace('\\n','')) \n",
        "\n",
        "##### código novo\n",
        "            dados_all.append(data[0]) # mes - isso ta dentro do loop que coleta os dados; para repetir a data de cada tabela\n",
        "            # nao pegamos o data[1] porque ele era 'de', que separava 'Janeiro de 2022', por exemplo\n",
        "            dados_all.append(data[2]) # ano - idem\n",
        "\n",
        "            final_data.append(dados_all) # no loop, guardamos dentro de 'final_data' o conteúdo 'dados_all'\n",
        "            #print(final_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Vamos transformar o nosso dado em DataFrame, definindo também o cabeçalho"
      ],
      "metadata": {
        "id": "Gg5jxZMU0dRn"
      },
      "id": "Gg5jxZMU0dRn"
    },
    {
      "cell_type": "code",
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\",id=True) \n",
        "\n",
        "for div in divs_link:\n",
        "\n",
        "    tabelas = div.find_all(\"table\")\n",
        "    if(tabelas): \n",
        "      titulos = div.find_all('b')\n",
        "      if(titulos): \n",
        "        data = str(titulos[0].get_text())[33:].split(' ')\n",
        "        \n",
        "        final_data = []\n",
        "        for tabela in tabelas: \n",
        "          linhas = tabela.find_all(\"tr\") \n",
        "          cabecalhos = linhas[0].find_all(\"th\") \n",
        "          #print(linhas)\n",
        "          cabecalhos_all = []\n",
        "\n",
        "          for cabecalho in cabecalhos: \n",
        "            cabecalhos_all.append(str(cabecalho.text).replace('\\xa0','crime')) \n",
        "\n",
        "          for linha in linhas[1:]: \n",
        "            dados = linha.find_all(\"td\") \n",
        "            \n",
        "            dados_all = [] \n",
        "            for dado in dados:\n",
        "              dados_all.append(str(dado.text).replace('\\n','')) \n",
        "\n",
        "            dados_all.append(data[0])\n",
        "            dados_all.append(data[2])\n",
        "            final_data.append(dados_all) \n",
        "            #print(final_df)\n",
        "\n",
        "##### código novo\n",
        "        cabecalhos_all.append('mes') # define 'mes' como nome do cabeçalho; append = acrescentar\n",
        "        cabecalhos_all.append('ano') # idem quanto a 'ano'\n",
        "      final_df = pd.DataFrame(final_data, columns = cabecalhos_all) # criamos o DataFrame e definimos o cabeçalho"
      ],
      "metadata": {
        "id": "Jy9z5DkQ0emk"
      },
      "id": "Jy9z5DkQ0emk",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Vamos deixar todos os dados em um único objeto e exportar como arquivo de planilha CSV ou XLSX"
      ],
      "metadata": {
        "id": "Hf9ZaI_p0Pcn"
      },
      "id": "Hf9ZaI_p0Pcn"
    },
    {
      "cell_type": "code",
      "source": [
        "##### código já explicado acima\n",
        "divs_link = soup.find_all(\"div\",id=True) \n",
        "\n",
        "final = pd.DataFrame()\n",
        "\n",
        "for div in divs_link:\n",
        "\n",
        "    tabelas = div.find_all(\"table\")\n",
        "    if(tabelas): \n",
        "      titulos = div.find_all('b')\n",
        "      if(titulos): \n",
        "        data = str(titulos[0].get_text())[33:].split(' ')\n",
        "        \n",
        "        final_data = [] \n",
        "        for tabela in tabelas: \n",
        "          linhas = tabela.find_all(\"tr\") \n",
        "          cabecalhos = linhas[0].find_all(\"th\") \n",
        "          #print(linhas)\n",
        "          cabecalhos_all = []\n",
        "\n",
        "          for cabecalho in cabecalhos: \n",
        "            cabecalhos_all.append(str(cabecalho.text).replace('\\xa0','crime')) \n",
        "\n",
        "          for linha in linhas[1:]: \n",
        "            dados = linha.find_all(\"td\") \n",
        "            \n",
        "            dados_all = [] \n",
        "            for dado in dados: \n",
        "              dados_all.append(str(dado.text).replace('\\n','')) \n",
        "\n",
        "            dados_all.append(data[0])\n",
        "            dados_all.append(data[2])\n",
        "            final_data.append(dados_all) \n",
        "            #print(final_df)\n",
        "\n",
        "        cabecalhos_all.append('mes')\n",
        "        cabecalhos_all.append('ano')\n",
        "      final_df = pd.DataFrame(final_data, columns = cabecalhos_all) \n",
        "\n",
        "##### código novo\n",
        "      #print()   \n",
        "      #print('3\\n\\n\\n\\n\\n\\n')\n",
        "\n",
        "      final = pd.concat([final, final_df]) # para cada tabela, vamos concatenar (empilhar) e criar um DataFrame\n",
        "\n",
        "      #print(final) \n",
        "final.to_excel(\"estatistica-violencia-contra-mulher.xlsx\", index=False) # download para xlsx\n",
        "final.to_csv(\"estatistica-violencia-contra-mulher.csv\", index=False) # download para csv"
      ],
      "metadata": {
        "id": "Vdb12BXM0T61"
      },
      "id": "Vdb12BXM0T61",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obrigada!"
      ],
      "metadata": {
        "id": "wK9JKjUq-mRp"
      },
      "id": "wK9JKjUq-mRp"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "raspagem-site-ssp.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}